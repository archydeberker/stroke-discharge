{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_model_conditional(age, nihss, mrs):\n",
    "    example = np.concatenate([normalize(nihss, train_mean[0] ,train_std[0]),\n",
    "              normalize(age, train_mean[1] ,train_std[1]),\n",
    "              one_hot_mrs(mrs).reshape(1, -1)\n",
    "              ],\n",
    "             axis=1)\n",
    "  \n",
    "    probs = lm.predict_proba(example)\n",
    "    conditional_graphs(age, nihss, mrs, probs)\n",
    "    \n",
    "def conditional_graphs(age, nihss, mrs, probs):\n",
    "    g = sns.FacetGrid(df, col=\"MRS\",  hue='Outcome', legend_out=True)\n",
    "    g.map(sns.scatterplot, \"Age\", 'NIHSS', alpha=.5)\n",
    "    g.add_legend()\n",
    "    \n",
    "    plt.sca(g.axes[0][mrs])\n",
    "\n",
    "    plt.axvline(age, color='r')\n",
    "    plt.axhline(nihss, color='r')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    ax = plt.bar(np.arange(len(probs.reshape(-1,))), probs.reshape(-1,).tolist(), linewidth=.2)\n",
    "    plt.xticks(np.arange(len(probs.reshape(-1,))), outcome_dict.values())\n",
    "    plt.ylim([0, 1])\n",
    "    plt.title('Predictions')\n",
    "    \n",
    "    \n",
    "interactive_plot = interactive(plot_predictions_model_conditional, age=(0, 100, 2), nihss=(0, 35, 1), mrs=(0, 5, 1))\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '500px'\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations\n",
    "\n",
    "## Dimensions\n",
    "\n",
    "The first concept we're going to tackle is that of a dimension. You're probably used to thinking about dimensions in space. Space, as you've probably heard, is 3D. \n",
    "\n",
    "What does that mean? It means that I can describe where you are - or where this ball is - using 3 numbers. By convention, these are often called `x, y, z`. I can make those numbers really precise - adding lots of decimal places - but there's no need for more than 3 numbers.\n",
    "\n",
    "[3D graph with ball]\n",
    "\n",
    "What happens if I try and describe where you are using just 2 numbers? It's ambigious. I can specify where you are in terms of longitude or latitude, but you could be at any height. Or I can choose to specify your height, and longitude, but then you could be at any latitude.\n",
    "\n",
    "[3D graph but with 2D controls]\n",
    "\n",
    "What if I want to specify your position in time? How many numbers do I need? Just 1 - your position in time can be represented just by a single number. That's why it's called a timeline:\n",
    "\n",
    "[Timeline]\n",
    "\n",
    "And so if we want to specify somebody's position in space and time, we're going to need 4 dimensions - 3 for space, and 1 for time.\n",
    "\n",
    "And actually, that's really hard to draw. Unfortunately, so are most of the spaces we're going to tackle in this piece. Because once you start looking for them, high dimensional spaces are everywhere. Let's look at the stats for one of my childhood idols, diminuitive rugby player Jason Robinson:\n",
    "\n",
    "Mat\tStart\tSub\tPts\tTries\tConv\tPens\tDrop\tWon\tLost\tDraw\t%\n",
    "\n",
    "overall\t2001-2007\t56\t52\t4\t150\t30\t0\t0\t0\t39\t17\t0\n",
    "\n",
    "So we have numbers corresponding to the number of matches he played, started, appeared as substitute, how many points he scored, how many tries he scored, how many conversions, penalties, dropgoals he scored, and how many games he won, lost and drew, and his winning percentage.\n",
    "\n",
    "So what do we have? That's right, we have a 12 dimensional space.\n",
    "\n",
    "Every rugby player in the `ESPN` database can be represented as a point in this space. Here are a couple more:\n",
    "\n",
    "x\n",
    "y\n",
    "x\n",
    "\n",
    "If you're used to working with spreadsheets or databases, you're probably thinking: oh I get it, dimensions are basically like columns in my spreadsheet. And that's exactly right - you can think of each row in your database as a point in a high-dimensional space defined by the columns.\n",
    "\n",
    "\n",
    "### Why does this matter?\n",
    "Machine learning is (more or less) the business of predicting some dimensions given some others.\n",
    "\n",
    "Let's dig into this given the examples we have so far. An example might be:\n",
    "\n",
    "1. Predicting longitude based upon latitude\n",
    "2. Predicting height above the earth based upon longitude and latitude\n",
    "3. Predicting how many points you've scored based upon how many tries, conversions, and dropgoals you've socred\n",
    "\n",
    "These range in difficulty, from very hard to very easy. You can probably see this intuitively: \n",
    "\n",
    "1. If I know your latitude, I can draw a line upon which your longitude might lie. But there are lots of different possible latitudes for a given longitude. The fact that you're unlikely to be in the sea probably helps, but we probably can't be super precise.\n",
    "\n",
    "\n",
    "2. If I know your latitude and longitude, I might actually be able to say quite alot about how high you are above the earth. For instance, if you're in New York, then you're likely to be higher above the earth than if you're in rural Zimbabwe. \n",
    "\n",
    "\n",
    "3. This one's actually trivial, because the number of points you scored is a product of the tries, conversions, and dropgoals you've scored! So there's a very simple mathematical rule we could write down to describe this relationship. But actually, we could learn it from the data too, as we'll show.\n",
    "\n",
    "\n",
    "Is life really this simple? Is all machine learning predicting one column of a database from a bunch of the others? Almost. So let's think about Go, the ancient Chinese game that DeepMind cracked using something called Deep Reinforcement Learning.\n",
    "\n",
    "Can we build this kind of 'database-style' representation? It's kind of tricky. We want to be able to pick the next move we make. Let's think about the ingredients we need:\n",
    "\n",
    "- For every position on the board, whether there is a white piece there, a black piece there, or neither\n",
    "- Whether that move was good or not\n",
    "\n",
    "The ingredients are simple, but actually getting them is rather hard:\n",
    "\n",
    "- a Go board is 19 x 19, so there are 361 positions that we need to specify. That's ok - we can have 361 columns. Unfortunately, we're going to need a lot of examples to understand what each column means. Imagine a sport you've never heard of (like, I don't know, rugby), where somebody gives you 361 numbers to describe how good each player is, along with an answer of how good that player actually is. You're going to need *a lot* of examples of players to figure out the significance of each of those columns.\n",
    "\n",
    "- We don't actually have access to that information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stroke-discharge",
   "language": "python",
   "name": "stroke-discharge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
